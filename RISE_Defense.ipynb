{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tk in /anaconda3/lib/python3.6/site-packages (0.1.0)\n",
      "\u001b[33mYou are using pip version 19.3.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pycairo in /anaconda3/lib/python3.6/site-packages (1.19.1)\n",
      "\u001b[33mYou are using pip version 19.3.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: palettable in /anaconda3/lib/python3.6/site-packages (3.3.0)\n",
      "\u001b[33mYou are using pip version 19.3.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tk\n",
    "!pip install pycairo\n",
    "!pip install palettable\n",
    "import matplotlib as mpl\n",
    "mpl.use('TKCairo')\n",
    "#import data_processing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "#IFrame(src='./dimension_reduced_TSNE.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<dl>\n",
    "  <H2 align=\"center\"> Welcome To Committee Meeting </H2>\n",
    "  <H1 align=\"center\"> Specific Aims </H1>\n",
    "\n",
    "</dl>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<dl>\n",
    "  <H1 align=\"center\"> Specific Aims: </H1>\n",
    "\n",
    "</dl>\n",
    "\n",
    "* Characterize and evaluate region-specific differences of cortical neuron-type data and models. \n",
    "\n",
    "* Using large, publicly available datasets for neuron classes, we will characterize region-specific differences and evaluate neuron-type models for agreement with experimental data \n",
    "\n",
    "* Using models of neuron-types from different cortical regions we will identify the features underlying differences among neuron types and across regions, as well as the biophysical mechanisms that underlie those features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<dl>\n",
    "  <H1 align=\"center\"> Regionlality </H1>\n",
    "\n",
    "</dl>\n",
    "\n",
    "* So far I have built tools that will enable me to explore the effects of region on cell models and cell data\n",
    "* But I have not actually applied the code to this question yet.\n",
    "* Instead I have been exploring a different question:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Does the variance in models represent Variance in Data?\n",
    "* Answer question by Applying:\n",
    "* t Distributed Spatial Embedding of Models and Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"./dimension_reduced_TSNE.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109cf1710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./dimension_reduced_TSNE.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There are some effects of region in Data and Models.\n",
    "\n",
    "To properly explore regions, it probably makes sense to interrogate region in data and models seperately.\n",
    "With everything together, however, you can see that the Allen Brain Data V1 layer IV Primary Visual Cortex are all clustered together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Isometric Map of t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"./dimension_reduced_PCA.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109cf16a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./dimension_reduced_PCA.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"./Everything_3D_scatter_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109cf13c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./Everything_3D_scatter_plot.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<dl>\n",
    "  <H1 align=\"center\"> Challenges and Set Backs. </H1>\n",
    "\n",
    "</dl>\n",
    "Izhikitich Equation leads is hard to optimize for 10 sets a\n",
    "\n",
    "Better to performance if broken into two parameter sets, dealing with Capacitance seperately\n",
    "\n",
    "\n",
    "* USE updating GEN dependent population size (sampling)\n",
    "# MU = 150\n",
    "# MU = 10\n",
    "* Object Orientated Design is at odds with memory friendly parallel code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<dl>\n",
    "  <H1 align=\"center\"> Resume Type Slide</H1>\n",
    "\n",
    "</dl>\n",
    "* Publications etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0349662a49d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_processing'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_data = df[bbp]\n",
    "temp_bbpindex = [i for i,idx in enumerate(df_data.index.values) if idx in stable_list]\n",
    "temp_bbpindex\n",
    "\n",
    "df_data = pd.concat([experiment_df,df_data])\n",
    "temp_allenindex = list(range(len(temp_bbpindex),len(df_data)))\n",
    "\n",
    "\n",
    "\n",
    "isomap = Isomap(n_components=2)\n",
    "isomap.fit(df_data.values)\n",
    "iso_data = isomap.embedding_.T\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "\n",
    "\n",
    "plt.scatter(iso_data[0,temp_bbpindex],iso_data[1,temp_bbpindex],c='green',cmap='rainbow',label='BBP data')\n",
    "plt.scatter(iso_data[0,temp_allenindex],iso_data[1,temp_allenindex],c='red',cmap='rainbow',label='Allen data')\n",
    "plt.scatter(iso_data[0,:],iso_data[1,:],c='red',cmap='rainbow',label='Allen data')\n",
    "\n",
    "legend = ax.legend()#handles, labels, loc=\"upper right\", title=\"Sizes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_data))\n",
    "print(np.shape(iso_data))\n",
    "print(len(set(iso_data[0,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = indexs['df']\n",
    "experiment_idx = indexs['experiment_idx']\n",
    "groundtruth = np.array(df.index.isin(experiment_idx))\n",
    "indexs.keys()\n",
    "#Y = indexs['exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_models_idx = df[new_model_labels].index\n",
    "#new_models_idx\n",
    "\n",
    "#gouwens_idx = df[gouwens_idx_labels].index\n",
    "#markram_idx = df[markram_idx_labels].index\n",
    "#df[markram_idx_labels]\n",
    "#bbpindex = df[bbp].index\n",
    "\n",
    "bbp = []\n",
    "for idx in df.index.values:\n",
    "    if idx in stable_list:\n",
    "        bbp.append(True)\n",
    "    else:\n",
    "        bbp.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('traub.p','rb') as f:\n",
    "    traub = pickle.load(f)\n",
    "traub_check = list(traub.values())\n",
    "traubindex = traub_check[0][0]\n",
    "traub_idx = [idx for idx in df.index.values if idx in traubindex]\n",
    "traub_idx_labels = [i for i in traub_idx]\n",
    "traub_idx_labels = df.index.isin(traub_idx)\n",
    "traub_cells = df[df.index.isin(traub_idx)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.manifold import Isomap, TSNE\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "\n",
    "# Turn all features into Normal(0,1) variables\n",
    "# Important since features all have different scales\n",
    "ss = StandardScaler()\n",
    "df[:] = ss.fit_transform(df.values)\n",
    "df.groupby(df.index).first()\n",
    "df = pd.DataFrame.drop_duplicates(df)\n",
    "\n",
    "\n",
    "\n",
    "isomap = Isomap(n_components=2)\n",
    "isomap.fit(df.values)\n",
    "iso = isomap.embedding_.T\n",
    "\n",
    "n_features = df.shape[1]\n",
    "\n",
    "n_components = 2\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X = copy.copy(df.values)\n",
    "#pca.fit(X)\n",
    "#transformed = pca.transform(df.values)\n",
    "\n",
    "#pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "n_components = 2\n",
    "ipca = IncrementalPCA(n_components=n_components, batch_size=10)\n",
    "X_ipca = ipca.fit_transform(X)\n",
    "\n",
    "\n",
    "#colors = ['navy', 'turquoise', 'darkorange']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(transformed)\n",
    "\n",
    "iso = isomap.embedding_.T\n",
    "\n",
    "#classif = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "\n",
    "#classif.fit(X, Y)\n",
    "np.shape(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trace0=(X_pca[0,experiment_idx_labels],X_pca[1,experiment_idx_labels],'Allen Brain Experimental Data',experiment_idx)\n",
    "#trace1=(X_pca[0,traub_idx_labels],X_pca[1,traub_idx_labels],'Traub cells',traub_idx)\n",
    "trace2=(X_pca[0,new_model_labels],X_pca[1,new_model_labels],'optimized models',new_models_idx)\n",
    "trace3=(X_pca[0,gouwens_idx_labels],X_pca[1,gouwens_idx_labels],'Gouwens models',gouwens_idx)\n",
    "trace4=(X_pca[0,markram_idx_labels],X_pca[1,markram_idx_labels],'Markram models',markram_idx)\n",
    "\n",
    "trace5=([X_pca[0,experiment_idx_labels][42]],[X_pca[1,experiment_idx_labels]],'Layer 4 aspiny 313862167',experiment_idx_labels)\n",
    "trace6=([X_pca[0,gouwens_idx_labels][-7]],[X_pca[1,gouwens_idx_labels][-7]],'Layer 4 spiny 479728896',gouwens_idx_labels)\n",
    "#plt.scatter(iso[0,regular_iz_idx_labels],iso[1,regular_iz_idx_labels],c='black',cmap='rainbow',label='Gouwens models')\n",
    "#trace7=([iso[0,regular_iz_idx_labels]],[iso[1,regular_iz_idx_labels]],'regular_iz_idx_labels',regular_iz_idx_labels)\n",
    "trace7=([X_pca[0,bbp]],[X_pca[1,bbp]],'Blue Brain Project Ephys Data',bbpindex)\n",
    "\n",
    "#trace7=(iso[0,bbp],iso[1,bbp],'Blue Brain Project Ephys Data',df[bbpindex].index.values)\n",
    "\n",
    "traces = [trace2,trace3,trace4,trace5,trace6,trace7]\n",
    "cnt=0\n",
    "theme = px.colors.diverging.Portland\n",
    "\n",
    "for i,ttt in enumerate(traces):\n",
    "    if cnt==len(theme):\n",
    "        cnt=0\n",
    "    size = 12\n",
    "\n",
    "    #if type(ttt[3]) is not type(str()):\n",
    "    text = df[df.index.isin(ttt[3])].index\n",
    "  \n",
    "    trace = dict(\n",
    "        type='scatter',\n",
    "        text=text,\n",
    "        x=ttt[0],\n",
    "        y=ttt[1],\n",
    "        mode='markers',\n",
    "        name=ttt[2],\n",
    "        marker=dict(\n",
    "            color=theme[cnt],\n",
    "            size=size,\n",
    "            line=dict(\n",
    "                color='rgba(217, 217, 217, 0.14)',\n",
    "                width=0.5),\n",
    "            opacity=0.8)\n",
    "    )\n",
    "    data.append(trace)\n",
    "    cnt+=1\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=data,\n",
    "    layout_title_text=\"steady_state_voltage_stimend_3.0x versus AP1DelayMeanTest_3.0x\"\n",
    ")#,\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1050,\n",
    "    height=1050\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dark2_7.mpl_colormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "import palettable\n",
    "cmap = ListedColormap(palettable.colorbrewer.qualitative.Dark2_7.mpl_colors)\n",
    "cmap.colors\n",
    "theme = None\n",
    "px = None\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "theme = px.colors.diverging.Portland\n",
    "#c\n",
    "\n",
    "#colours = [c for c in cmap.colors ]\n",
    "\n",
    "theme.extend(cmap.colors)\n",
    "#theme = None\n",
    "#colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "from palettable.colorbrewer.qualitative import Dark2_7\n",
    "cmap = palettable.colorbrewer.diverging\n",
    "cmap\n",
    "experiment_idx_labels = indexs['experiment_idx_labels']\n",
    "model_index_labels = indexs['model_index_labels']\n",
    "new_model_labels = indexs['new_model_labels']\n",
    "gouwens_idx_labels = indexs['gouwens_idx_labels']\n",
    "experiment_idx_labels = indexs['experiment_idx_labels']\n",
    "markram_idx_labels = indexs['markram_idx_labels']\n",
    "bbp = indexs['bbp']\n",
    "\n",
    "trace0=(iso[0,experiment_idx_labels],iso[1,experiment_idx_labels],'Allen Brain Experimental Data',experiment_idx)\n",
    "trace1=(iso[0,model_index_labels],iso[1,model_index_labels],'models',model_idx)\n",
    "trace2=(iso[0,new_model_labels],iso[1,new_model_labels],'optimized models',new_models_idx)\n",
    "trace3=(iso[0,gouwens_idx_labels],iso[1,gouwens_idx_labels],'Gouwens models',gouwens_idx)\n",
    "trace4=(iso[0,markram_idx_labels],iso[1,markram_idx_labels],'Markram models',markram_idx)\n",
    "\n",
    "trace5=([iso[0,experiment_idx_labels][42]],[iso[1,experiment_idx_labels]],'Layer 4 aspiny 313862167',experiment_idx_labels)\n",
    "trace6=([iso[0,gouwens_idx_labels][-7]],[iso[1,gouwens_idx_labels][-7]],'Layer 4 spiny 479728896',gouwens_idx_labels)\n",
    "#plt.scatter(iso[0,regular_iz_idx_labels],iso[1,regular_iz_idx_labels],c='black',cmap='rainbow',label='Gouwens models')\n",
    "#trace7=([iso[0,regular_iz_idx_labels]],[iso[1,regular_iz_idx_labels]],'regular_iz_idx_labels',regular_iz_idx_labels)\n",
    "#trace7=([iso[0,bbp]],[iso[1,bbp]],'BBP',df[bbpindex].index.values)\n",
    "#trace7=(iso[0,bbp],iso[1,bbp],'Blue Brain Project Ephys Data',df[bbpindex].index.values)\n",
    "trace7=(iso[0,bbp],iso[1,bbp],'Blue Brain Project Ephys Data',bbpindex)\n",
    "\n",
    "#plt.scatter(iso[0,bbp_labels],iso[1,bbp_labels],s=10, c='purple',cmap='rainbow',label='BBP')\n",
    "trace8=(iso[0,traub_idx_labels],iso[1,traub_idx_labels],'Traub cells',traub_idx)\n",
    "\n",
    "traces = [trace0,trace1,trace2,trace3,trace4,trace5,trace6,trace7,trace8]\n",
    "cnt=0\n",
    "\n",
    "for i,ttt in enumerate(traces):\n",
    "    if cnt==len(theme):\n",
    "        cnt=0\n",
    "    if i>1:\n",
    "        size = 12\n",
    "    else:\n",
    "        size = 6\n",
    "        #if type(ttt[3]) is not type(str()):\n",
    "        text = df[df.index.isin(ttt[3])].index\n",
    "  \n",
    "    trace = dict(\n",
    "        type='scatter',\n",
    "        text=text,\n",
    "        x=ttt[0],\n",
    "        y=ttt[1],\n",
    "        mode='markers',\n",
    "        name=ttt[2],\n",
    "        marker=dict(\n",
    "            color=theme[cnt],\n",
    "            size=size,\n",
    "            line=dict(\n",
    "                color='rgba(217, 217, 217, 0.14)',\n",
    "                width=0.5),\n",
    "            opacity=0.8)\n",
    "    )\n",
    "    data.append(trace)\n",
    "    cnt+=1\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=data,\n",
    "    layout_title_text=\"steady_state_voltage_stimend_3.0x versus AP1DelayMeanTest_3.0x\"\n",
    ")#,\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1050,\n",
    "    height=1050\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperplane(clf, min_x, max_x):\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(min_x - 5, max_x + 5)  # make sure the line is long enough\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "    plt.plot(xx, yy)#, linestyle, label=label)\n",
    "def get_hyperplane(clf, min_x, max_x):\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(min_x - 5, max_x + 5)  # make sure the line is long enough\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "    #plt.plot(xx, yy, linestyle, label=label)\n",
    "    return (xx,yy)\n",
    "def plot_subfigure(X, Y, title, transform):\n",
    "    if transform == \"pca\":\n",
    "        X = PCA(n_components=2).fit_transform(X)\n",
    "    elif transform == \"cca\":\n",
    "        X = CCA(n_components=2).fit(X, Y).transform(X)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    classif = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "\n",
    "    classif.fit(X, Y)\n",
    "    xx,yy = get_hyperplane(classif.estimators_[0], min_x, max_x)#, 'k--',\n",
    "    print(xx,yy)\n",
    "    #plt.subplot(2, 2)\n",
    "    plt.clf()\n",
    "    plt.title(title)\n",
    "\n",
    "    zero_class = Y#np.where(Y[:, 0])\n",
    "    one_class = ~Y#np.where(Y[:, 1])\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=40, c='gray', edgecolors=(0, 0, 0))\n",
    "    plt.scatter(X[zero_class, 0], X[zero_class, 1], s=160, edgecolors='b',\n",
    "                facecolors='none', linewidths=2, label='Class 1')\n",
    "    plt.scatter(X[one_class, 0], X[one_class, 1], s=80, edgecolors='orange',\n",
    "                facecolors='none', linewidths=2, label='Class 2')\n",
    "\n",
    "    xx,yy = get_hyperplane(classif.estimators_[0], min_x, max_x)#, 'k--',\n",
    "    #                'Boundary\\nfor class 1')\n",
    "    #xx,yy = get_hyperplane(classif.estimators_[1], min_x, max_x)#, 'k-.',\n",
    "    #                'Boundary\\nfor class 2')\n",
    "    \n",
    "    plot_hyperplane(classif.estimators_[0], min_x, max_x)#, 'k--',\n",
    "    #                'Boundary\\nfor class 1')\n",
    "    #plot_hyperplane(classif.estimators_[1], min_x, max_x)#, 'k-.',\n",
    "    #                'Boundary\\nfor class 2')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    #plt.xlim(min_x - .5 * max_x, max_x + .5 * max_x)\n",
    "    #plt.ylim(min_y - .5 * max_y, max_y + .5 * max_y)\n",
    "    #if subplot == 2:\n",
    "    plt.xlabel('First principal component')\n",
    "    plt.ylabel('Second principal component')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    return plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_subfigure(df.values, groundtruth, \"hello\", transform=\"pca\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df),len(groundtruth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "included = []\n",
    "excluded = []\n",
    "for col0 in df.columns:\n",
    "    if col0 in df_o_m.columns: \n",
    "        included.append(copy.copy(col0))\n",
    "        included[-1] in df_o_m.columns  \n",
    "    else:\n",
    "        excluded.append(col0)\n",
    "        excluded[-1] in df.columns  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "included_ = []\n",
    "excluded_ = []\n",
    "for col0 in df_o_m.columns:\n",
    "    if col0 in df.columns: \n",
    "        included_.append(copy.copy(col0))\n",
    "        included_[-1] in df_o_m.columns  \n",
    "    else:\n",
    "        excluded_.append(col0)\n",
    "        excluded_[-1] in df.columns  \n",
    "\n",
    "\n",
    "\n",
    "df_o_m = df_o_m[included_]\n",
    "df_o_m\n",
    "\n",
    "\n",
    "\n",
    "df_combined = df[included]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "X = df_combined.values\n",
    "\n",
    "\n",
    "df_o_m.values;\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "rfc.fit(X, groundtruth)\n",
    "predictions = rfc.predict(df_o_m.values)\n",
    "print(len(df_o_m.values))\n",
    "print(predictions)\n",
    "print(len(df_o_m.values[1]))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "fig = plt.figure()\n",
    "\n",
    "X = x.T\n",
    "\n",
    "rfc.fit(x.T, groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "autolaunch": true
  },
  "rise": {
   "autolaunch": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
